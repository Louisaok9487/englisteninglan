<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è‹±èªå­¸ç¿’æ‡‰ç”¨ç¨‹å¼</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for better aesthetics and responsiveness */
        body {
            font-family: "Inter", sans-serif;
            background-color: #f0f2f5; /* Light grey background */
            display: flex;
            justify-content: center;
            align-items: flex-start; /* Align to top for better content flow */
            min-height: 100vh;
            padding: 20px;
            box-sizing: border-box;
        }
        .app-container {
            background-color: #ffffff;
            border-radius: 16px; /* More rounded corners */
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1); /* Softer shadow */
            width: 100%;
            max-width: 800px; /* Max width for desktop */
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }
        .tab-button {
            padding: 1rem 1.5rem;
            font-weight: 600;
            color: #4b5563; /* Grey text */
            border-bottom: 3px solid transparent;
            transition: all 0.3s ease;
        }
        .tab-button.active {
            color: #1d4ed8; /* Blue text */
            border-color: #1d4ed8; /* Blue underline */
        }
        .content-section {
            padding: 1.5rem;
            display: none; /* Hidden by default */
        }
        .content-section.active {
            display: block; /* Shown when active */
        }

        /* Styling for buttons */
        .btn {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            padding: 0.75rem 1.5rem;
            border-radius: 9999px; /* Pill shape */
            font-weight: 600;
            transition: all 0.2s ease-in-out;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            border: none; /* Remove default border */
            cursor: pointer;
        }
        .btn-primary {
            background-color: #3b82f6; /* Blue */
            color: white;
        }
        .btn-primary:hover {
            background-color: #2563eb; /* Darker blue */
            transform: translateY(-2px); /* Lift effect */
            box-shadow: 0 6px 10px rgba(0, 0, 0, 0.15);
        }
        .btn-secondary {
            background-color: #e5e7eb; /* Light grey */
            color: #374151; /* Dark grey text */
        }
        .btn-secondary:hover {
            background-color: #d1d5db; /* Darker light grey */
            transform: translateY(-2px);
            box-shadow: 0 6px 10px rgba(0, 0, 0, 0.15);
        }
        .btn-danger {
            background-color: #ef4444; /* Red */
            color: white;
        }
        .btn-danger:hover {
            background-color: #dc2626; /* Darker red */
            transform: translateY(-2px);
            box-shadow: 0 6px 10px rgba(0, 0, 0, 0.15);
        }

        /* Input styling */
        .input-field {
            width: 100%;
            padding: 0.75rem 1rem;
            border-radius: 8px;
            border: 1px solid #d1d5db;
            font-size: 1rem;
            transition: border-color 0.2s ease;
        }
        .input-field:focus {
            outline: none;
            border-color: #3b82f6;
            box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.25);
        }

        /* Message Box Styling */
        .message-box {
            background-color: #fefcbf; /* Light yellow */
            border: 1px solid #fcd34d; /* Yellow border */
            color: #92400e; /* Dark brown text */
            padding: 1rem;
            border-radius: 8px;
            margin-top: 1rem;
            display: none; /* Hidden by default */
        }
        .message-box.show {
            display: block;
        }

        /* Specific styles for conversation display */
        .conversation-line {
            padding: 0.5rem 0;
            border-bottom: 1px dashed #e5e7eb;
        }
        .conversation-line:last-child {
            border-bottom: none;
        }
        .option-button {
            width: 100%;
            text-align: left;
            padding: 0.75rem 1rem;
            border-radius: 8px;
            border: 1px solid #d1d5db;
            background-color: #f9fafb;
            transition: all 0.2s ease;
        }
        .option-button:hover:not(:disabled) {
            background-color: #e5e7eb;
            border-color: #9ca3af;
        }
        .option-button.selected {
            border-color: #3b82f6;
            background-color: #dbeafe;
            font-weight: 600;
        }
        .option-button:disabled {
            opacity: 0.7;
            cursor: not-allowed;
        }
    </style>
</head>
<body class="antialiased">
    <div class="app-container">
        <!-- Tab Navigation -->
        <div class="flex border-b border-gray-200">
            <button id="listeningTabBtn" class="tab-button active flex-1 text-center">è½åŠ›ç·´ç¿’ ğŸ§</button>
            <button id="speakingTabBtn" class="tab-button flex-1 text-center">å£èªªç·´ç¿’ ğŸ—£ï¸</button>
        </div>

        <!-- Listening Practice Tab Content -->
        <div id="listeningContent" class="content-section active">
            <h2 class="text-2xl font-bold text-gray-800 mb-6">è½åŠ›ç·´ç¿’</h2>

            <!-- Accent Selection -->
            <div class="mb-6 p-4 bg-blue-50 rounded-lg shadow-sm">
                <h3 class="text-xl font-semibold text-gray-700 mb-4">é¸æ“‡å£éŸ³</h3>
                <div class="flex flex-wrap gap-3">
                    <button id="usAccentBtn" class="btn btn-secondary">ç¾å¼å£éŸ³ ğŸ‡ºğŸ‡¸</button>
                    <button id="ukAccentBtn" class="btn btn-primary">è‹±å¼å£éŸ³ ğŸ‡¬ğŸ‡§</button>
                </div>
            </div>

            <!-- Listening Comprehension Quiz -->
            <div class="p-4 bg-green-50 rounded-lg shadow-sm">
                <h3 class="text-xl font-semibold text-gray-700 mb-4">æƒ…å¢ƒå°è©±ç†è§£</h3>
                <p class="text-gray-600 mb-4">ä»”ç´°è†è½å°è©±ï¼Œç„¶å¾Œå›ç­”å•é¡Œã€‚</p>

                <div id="conversationDisplay" class="bg-white p-4 rounded-lg shadow-inner mb-6 min-h-[120px] flex flex-col justify-center">
                    <!-- Conversation lines will be inserted here -->
                    <p class="text-gray-500 italic">é»æ“Šã€Œæ’­æ”¾å°è©±ã€é–‹å§‹ã€‚</p>
                </div>

                <div class="flex flex-col sm:flex-row gap-3 mb-4">
                    <button id="playConversationBtn" class="btn btn-primary flex-1">æ’­æ”¾å°è©± â–¶ï¸</button>
                    <button id="pauseConversationBtn" class="btn btn-secondary flex-1" disabled>æš«åœ â¸ï¸</button>
                    <button id="stopConversationBtn" class="btn btn-danger flex-1" disabled>åœæ­¢ â¹ï¸</button>
                    <button id="nextScenarioBtn" class="btn btn-secondary flex-1">ä¸‹ä¸€å€‹æƒ…å¢ƒ â¡ï¸</button>
                </div>

                <p id="scenarioQuestion" class="text-lg font-semibold text-gray-800 mb-4 mt-4 hidden">å•é¡Œï¼š</p>
                <div id="optionsContainer" class="grid grid-cols-1 gap-3 mb-4">
                    <!-- Options buttons will be inserted here -->
                </div>

                <div class="flex flex-wrap gap-3">
                    <button id="checkAnswerBtn" class="btn btn-primary" disabled>æª¢æŸ¥ç­”æ¡ˆ âœ…</button>
                    <button id="showTranscriptBtn" class="btn btn-secondary" disabled>é¡¯ç¤ºä¸­æ–‡åŸæ–‡ ğŸ“–</button>
                </div>
                <p id="quizFeedback" class="text-lg font-semibold mt-4"></p>
                <p id="quizTranscriptDisplay" class="text-gray-700 mt-2 italic hidden whitespace-pre-wrap"></p>
            </div>
        </div>

        <!-- Speaking Practice Tab Content -->
        <div id="speakingContent" class="content-section">
            <h2 class="text-2xl font-bold text-gray-800 mb-6">å£èªªç·´ç¿’</h2>

            <!-- Sentence Repetition -->
            <div class="mb-8 p-4 bg-purple-50 rounded-lg shadow-sm">
                <h3 class="text-xl font-semibold text-gray-700 mb-4">å¥å­é‡è¤‡</h3>
                <p class="text-gray-600 mb-4">é‡è¤‡ä¸‹é¢çš„å¥å­ä¸¦æª¢æŸ¥ä½ çš„ç™¼éŸ³ã€‚</p>
                <p id="targetSentence" class="text-xl font-medium text-blue-700 bg-blue-100 p-3 rounded-md mb-4">é»æ“Šã€Œä¸‹ä¸€å€‹å¥å­ã€é–‹å§‹ã€‚</p>
                <div class="flex flex-wrap gap-3 mb-4">
                    <button id="recordBtn" class="btn btn-primary">éŒ„éŸ³ ğŸ¤</button>
                    <button id="stopRecordBtn" class="btn btn-danger" disabled>åœæ­¢éŒ„éŸ³ â¹ï¸</button>
                    <button id="playOriginalBtn" class="btn btn-secondary" disabled>æ’­æ”¾åŸæ–‡ â–¶ï¸</button>
                    <button id="playMyRecordingBtn" class="btn btn-secondary" disabled>æ’­æ”¾æˆ‘çš„éŒ„éŸ³ ğŸ‘‚</button>
                    <button id="nextSpeakingSentenceBtn" class="btn btn-secondary">ä¸‹ä¸€å€‹å¥å­ â¡ï¸</button>
                </div>
                <p class="text-gray-600 mt-4">ä½ çš„è½‰éŒ„ï¼š</p>
                <p id="userTranscription" class="text-lg text-gray-800 bg-gray-100 p-3 rounded-md min-h-[50px]"></p>
                <p id="speakingFeedback" class="text-lg font-semibold mt-4"></p>
            </div>

            <!-- Free Speaking Mode -->
            <div class="p-4 bg-yellow-50 rounded-lg shadow-sm">
                <h3 class="text-xl font-semibold text-gray-700 mb-4">è‡ªç”±å£èªªæ¨¡å¼</h3>
                <p class="text-gray-600 mb-4">è‡ªç”±èªªè©±ä¸¦æŸ¥çœ‹ä½ çš„æ–‡å­—è½‰éŒ„ã€‚</p>
                <div class="flex flex-wrap gap-3 mb-4">
                    <button id="startFreeSpeakBtn" class="btn btn-primary">é–‹å§‹è‡ªç”±èªªè©± ğŸ™ï¸</button>
                    <button id="stopFreeSpeakBtn" class="btn btn-danger" disabled>åœæ­¢è‡ªç”±èªªè©± ğŸ›‘</button>
                </div>
                <p class="text-gray-600 mt-4">ä½ çš„è‡ªç”±èªªè©±è½‰éŒ„ï¼š</p>
                <p id="freeSpeechTranscription" class="text-lg text-gray-800 bg-gray-100 p-3 rounded-md min-h-[50px]"></p>
            </div>
        </div>

        <!-- Global Message Box -->
        <div id="messageBox" class="message-box"></div>
    </div>

    <script>
        // --- Global Variables and Initial Setup ---
        const appContainer = document.querySelector('.app-container');
        const listeningTabBtn = document.getElementById('listeningTabBtn');
        const speakingTabBtn = document.getElementById('speakingTabBtn');
        const listeningContent = document.getElementById('listeningContent');
        const speakingContent = document.getElementById('speakingContent');
        const messageBox = document.getElementById('messageBox');

        // Speech Synthesis (TTS)
        const synth = window.speechSynthesis;
        let currentUtterance = null; // To keep track of the current speaking utterance
        let isConversationPlaying = false;
        let isConversationPaused = false;
        let speaker1Voice = null; // Voice for speaker 1
        let speaker2Voice = null; // Voice for speaker 2
        let currentAccent = 'en-GB'; // Default accent for all speech

        // Speech Recognition (STT)
        let recognition = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let recordedAudioBlob = null;
        let audioContext = null;
        let sourceNode = null;

        // Sentences for speaking practice (unchanged from previous version)
        const speakingSentences = [
            "Hello, how are you today?",
            "Could you please pass me the salt?",
            "I would like to order a coffee, please.",
            "What time does the next train depart?",
            "It's a beautiful day for a walk.",
            "Thank you for your help, I really appreciate it.",
            "Where is the nearest supermarket?",
            "I am learning English and it's quite interesting.",
            "Could you repeat that, please?",
            "Nice to meet you."
        ];
        let currentSpeakingSentenceIndex = 0;

        // --- Listening Scenarios for Taiwan Daily Life ---
        const listeningScenarios = [
            {
                topic: "Asking for Direction (å•è·¯)",
                conversation: [
                    "Tourist: Excuse me, could you tell me how to get to Taipei 101?",
                    "Local: Of course! Go straight down this road, then turn left at the second traffic light.",
                    "Tourist: Straight, then left at the second light. Got it. Is it far from there?",
                    "Local: Not really. It's about a ten-minute walk. You can't miss it.",
                    "Tourist: Thank you so much for your help!",
                    "Local: You're welcome! Have a good day."
                ],
                chineseTranslation: "éŠå®¢ï¼šä¸å¥½æ„æ€ï¼Œè«‹å•å°åŒ—101æ€éº¼èµ°ï¼Ÿ\nç•¶åœ°äººï¼šç•¶ç„¶ï¼æ²¿è‘—é€™æ¢è·¯ç›´èµ°ï¼Œç„¶å¾Œåœ¨ç¬¬äºŒå€‹ç´…ç¶ ç‡ˆå·¦è½‰ã€‚\néŠå®¢ï¼šç›´èµ°ï¼Œç¬¬äºŒå€‹ç´…ç¶ ç‡ˆå·¦è½‰ã€‚çŸ¥é“äº†ã€‚é›¢é‚£è£¡é å—ï¼Ÿ\nç•¶åœ°äººï¼šä¸å¤ªé ã€‚å¤§ç´„èµ°ååˆ†é˜ã€‚ä½ ä¸æœƒéŒ¯éçš„ã€‚\néŠå®¢ï¼šéå¸¸æ„Ÿè¬æ‚¨çš„å¹«åŠ©ï¼\nç•¶åœ°äººï¼šä¸å®¢æ°£ï¼ç¥æ‚¨æœ‰ç¾å¥½çš„ä¸€å¤©ã€‚",
                question: "æ ¹æ“šå°è©±ï¼ŒéŠå®¢éœ€è¦åœ¨å“ªè£¡è½‰å½ï¼Ÿ",
                options: ["ç¬¬ä¸€å€‹ç´…ç¶ ç‡ˆ", "ç¬¬äºŒå€‹ç´…ç¶ ç‡ˆ", "ç¬¬ä¸‰å€‹ç´…ç¶ ç‡ˆ", "åœ¨è·¯å£å³è½‰"],
                correctAnswerIndex: 1,
                englishTranscript: "Tourist: Excuse me, could you tell me how to get to Taipei 101?\nLocal: Of course! Go straight down this road, then turn left at the second traffic light.\nTourist: Straight, then left at the second light. Got it. Is it far from there?\nLocal: Not really. It's about a ten-minute walk. You can't miss it.\nTourist: Thank you so much for your help!\nLocal: You're welcome! Have a good day."
            },
            {
                topic: "Ordering at a Restaurant (é¤å»³é»é¤)",
                conversation: [
                    "Waiter: Welcome! What can I get for you today?",
                    "Customer: Hi! I'd like a large bubble milk tea, half sugar, less ice.",
                    "Waiter: Half sugar, less ice, got it. Anything else?",
                    "Customer: Yes, and one beef noodle soup, please.",
                    "Waiter: Excellent choice! That'll be 250 NTD.",
                    "Customer: Here you go. Thank you!"
                ],
                chineseTranslation: "æœå‹™ç”Ÿï¼šæ­¡è¿å…‰è‡¨ï¼ä»Šå¤©æƒ³é»ä»€éº¼ï¼Ÿ\né¡§å®¢ï¼šå—¨ï¼æˆ‘æƒ³è¦ä¸€æ¯å¤§æ¯çç å¥¶èŒ¶ï¼ŒåŠç³–å°‘å†°ã€‚\næœå‹™ç”Ÿï¼šåŠç³–å°‘å†°ï¼Œå¥½çš„ã€‚é‚„æœ‰åˆ¥çš„å—ï¼Ÿ\né¡§å®¢ï¼šæ˜¯çš„ï¼Œå†åŠ ä¸€ä»½ç‰›è‚‰éºµï¼Œè¬è¬ã€‚\næœå‹™ç”Ÿï¼šå¾ˆæ£’çš„é¸æ“‡ï¼ç¸½å…±æ˜¯æ–°å°å¹£250å…ƒã€‚\né¡§å®¢ï¼šçµ¦ä½ ã€‚è¬è¬ï¼",
                question: "é¡§å®¢é»äº†ä»€éº¼é£²æ–™ï¼Ÿ",
                options: ["å’–å•¡", "ç¶ èŒ¶", "çç å¥¶èŒ¶", "æœæ±"],
                correctAnswerIndex: 2,
                englishTranscript: "Waiter: Welcome! What can I get for you today?\nCustomer: Hi! I'd like a large bubble milk tea, half sugar, less ice.\nWaiter: Half sugar, less ice, got it. Anything else?\nCustomer: Yes, and one beef noodle soup, please.\nWaiter: Excellent choice! That'll be 250 NTD.\nCustomer: Here you go. Thank you!"
            },
            {
                topic: "Airport Check-in (æ©Ÿå ´å ±åˆ°)",
                conversation: [
                    "Agent: Good morning! Passport and ticket, please.",
                    "Passenger: Good morning. Here you are.",
                    "Agent: Are you checking any bags today?",
                    "Passenger: Yes, just one suitcase.",
                    "Agent: Alright. Your gate is A12, and boarding starts at 9:30 AM.",
                    "Passenger: Thank you!"
                ],
                chineseTranslation: "æ«ƒæª¯äººå“¡ï¼šæ—©å®‰ï¼è«‹å‡ºç¤ºè­·ç…§å’Œæ©Ÿç¥¨ã€‚\nä¹˜å®¢ï¼šæ—©å®‰ã€‚çµ¦ä½ ã€‚\næ«ƒæª¯äººå“¡ï¼šä»Šå¤©æœ‰è¦è¨—é‹çš„è¡Œæå—ï¼Ÿ\nä¹˜å®¢ï¼šæ˜¯çš„ï¼Œåªæœ‰ä¸€å€‹è¡Œæç®±ã€‚\næ«ƒæª¯äººå“¡ï¼šå¥½çš„ã€‚æ‚¨çš„ç™»æ©Ÿé–€æ˜¯A12ï¼Œä¸Šåˆ9:30é–‹å§‹ç™»æ©Ÿã€‚\nä¹˜å®¢ï¼šè¬è¬ï¼",
                question: "ä¹˜å®¢æœ‰å¹¾ä»¶è¡Œæè¦è¨—é‹ï¼Ÿ",
                options: ["æ²’æœ‰", "ä¸€ä»¶", "å…©ä»¶", "ä¸‰ä»¶"],
                correctAnswerIndex: 1,
                englishTranscript: "Agent: Good morning! Passport and ticket, please.\nPassenger: Good morning. Here you are.\nAgent: Are you checking any bags today?\nPassenger: Yes, just one suitcase.\nAgent: Alright. Your gate is A12, and boarding starts at 9:30 AM.\nPassenger: Thank you!"
            },
            {
                topic: "Shopping at a Night Market (å¤œå¸‚è³¼ç‰©)",
                conversation: [
                    "Vendor: Hello! Can I help you?",
                    "Customer: Hi! How much is this T-shirt?",
                    "Vendor: That one is 350 NTD.",
                    "Customer: Hmm, is there a smaller size available?",
                    "Vendor: Yes, we have small and medium. Which one would you like?",
                    "Customer: I'll take the small, please."
                ],
                chineseTranslation: "æ”¤è²©ï¼šä½ å¥½ï¼éœ€è¦å¹«å¿™å—ï¼Ÿ\né¡§å®¢ï¼šå—¨ï¼é€™ä»¶Tæ¤å¤šå°‘éŒ¢ï¼Ÿ\næ”¤è²©ï¼šé‚£ä»¶æ˜¯æ–°å°å¹£350å…ƒã€‚\né¡§å®¢ï¼šå—¯ï¼Œæœ‰å°ä¸€é»çš„å°ºå¯¸å—ï¼Ÿ\næ”¤è²©ï¼šæœ‰ï¼Œæˆ‘å€‘æœ‰å°è™Ÿå’Œä¸­è™Ÿã€‚ä½ æƒ³è¦å“ªä¸€å€‹ï¼Ÿ\né¡§å®¢ï¼šæˆ‘æ‹¿å°è™Ÿçš„ï¼Œè¬è¬ã€‚",
                question: "é¡§å®¢æƒ³çŸ¥é“Tæ¤çš„ä»€éº¼è³‡è¨Šï¼Ÿ",
                options: ["é¡è‰²", "åƒ¹æ ¼", "æè³ª", "å“ç‰Œ"],
                correctAnswerIndex: 1,
                englishTranscript: "Vendor: Hello! Can I help you?\nCustomer: Hi! How much is this T-shirt?\nVendor: That one is 350 NTD.\nCustomer: Hmm, is there a smaller size available?",
            },
            {
                topic: "Taking a Taxi (æ­è¨ˆç¨‹è»Š)",
                conversation: [
                    "Passenger: Excuse me, are you free?",
                    "Driver: Yes, where are you going?",
                    "Passenger: To Ximending, please. How much will it be?",
                    "Driver: About 200 to 250 NTD, depending on traffic.",
                    "Passenger: Okay, let's go.",
                    "Driver: Hop in!"
                ],
                chineseTranslation: "ä¹˜å®¢ï¼šä¸å¥½æ„æ€ï¼Œä½ ç©ºè‘—å—ï¼Ÿ\nå¸æ©Ÿï¼šæ˜¯çš„ï¼Œä½ è¦å»å“ªè£¡ï¼Ÿ\nä¹˜å®¢ï¼šè«‹åˆ°è¥¿é–€ç”ºã€‚å¤§æ¦‚å¤šå°‘éŒ¢ï¼Ÿ\nå¸æ©Ÿï¼šå¤§ç´„æ–°å°å¹£200åˆ°250å…ƒï¼Œå–æ±ºæ–¼äº¤é€šç‹€æ³ã€‚\nä¹˜å®¢ï¼šå¥½çš„ï¼Œèµ°å§ã€‚\nå¸æ©Ÿï¼šä¸Šè»Šï¼",
                question: "è¨ˆç¨‹è»Šå¸æ©Ÿé ä¼°è»Šè³‡å¤§ç´„æ˜¯å¤šå°‘ï¼Ÿ",
                options: ["100-150å…ƒ", "200-250å…ƒ", "300-350å…ƒ", "400å…ƒä»¥ä¸Š"],
                correctAnswerIndex: 1,
                englishTranscript: "Passenger: Excuse me, are you free?\nDriver: Yes, where are you going?\nPassenger: To Ximending, please. How much will it be?\nDriver: About 200 to 250 NTD, depending on traffic.\nPassenger: Okay, let's go.\nDriver: Hop in!"
            },
            {
                topic: "Visiting a Temple (åƒè§€å»Ÿå®‡)",
                conversation: [
                    "Visitor: This temple is beautiful! How old is it?",
                    "Guide: It was built over 300 years ago, during the Qing Dynasty.",
                    "Visitor: Wow, that's amazing. What are these carvings about?",
                    "Guide: They depict stories from ancient Chinese folklore and mythology.",
                    "Visitor: Fascinating! Thank you for the information.",
                    "Guide: My pleasure."
                ],
                chineseTranslation: "éŠå®¢ï¼šé€™åº§å»ŸçœŸæ¼‚äº®ï¼å®ƒæœ‰å¤šä¹…æ­·å²äº†ï¼Ÿ\nå°éŠï¼šå®ƒå»ºæ–¼300å¤šå¹´å‰ï¼Œæ¸…æœæ™‚æœŸã€‚\néŠå®¢ï¼šå“‡ï¼Œå¤ªæ£’äº†ã€‚é€™äº›é›•åˆ»æ˜¯é—œæ–¼ä»€éº¼çš„ï¼Ÿ\nå°éŠï¼šå®ƒå€‘æç¹ªäº†ä¸­åœ‹å¤ä»£æ°‘é–“å‚³èªªå’Œç¥è©±æ•…äº‹ã€‚\néŠå®¢ï¼šçœŸå¼•äººå…¥å‹ï¼è¬è¬ä½ çš„è³‡è¨Šã€‚\nå°éŠï¼šä¸å®¢æ°£ã€‚",
                question: "é€™åº§å»Ÿå®‡å¤§ç´„å»ºæ–¼å¤šä¹…ä»¥å‰ï¼Ÿ",
                options: ["100å¤šå¹´å‰", "200å¤šå¹´å‰", "300å¤šå¹´å‰", "400å¤šå¹´å‰"],
                correctAnswerIndex: 2,
                englishTranscript: "Visitor: This temple is beautiful! How old is it?\nGuide: It was built over 300 years ago, during the Qing Dynasty.\nVisitor: Wow, that's amazing. What are these carvings about?\nGuide: They depict stories from ancient Chinese folklore and mythology.\nVisitor: Fascinating! Thank you for the information.",
            },
            {
                topic: "At a Convenience Store (ä¾¿åˆ©å•†åº—)",
                conversation: [
                    "Customer: Hi, I'd like this bottled water and a pack of tissues.",
                    "Clerk: Okay, that's 45 NTD in total.",
                    "Customer: Here's 50. Do you have a bag?",
                    "Clerk: Yes, we do. Here's your change and your items.",
                    "Customer: Thanks!",
                    "Clerk: You're welcome. Have a good day."
                ],
                chineseTranslation: "é¡§å®¢ï¼šå—¨ï¼Œæˆ‘æƒ³è¦é€™ç“¶æ°´å’Œä¸€åŒ…é¢ç´™ã€‚\nåº—å“¡ï¼šå¥½çš„ï¼Œç¸½å…±æ–°å°å¹£45å…ƒã€‚\né¡§å®¢ï¼šé€™æ˜¯50å…ƒã€‚ä½ å€‘æœ‰è¢‹å­å—ï¼Ÿ\nåº—å“¡ï¼šæ˜¯çš„ï¼Œæˆ‘å€‘æœ‰ã€‚é€™æ˜¯ä½ çš„æ‰¾é›¶å’Œä½ çš„å•†å“ã€‚\né¡§å®¢ï¼šè¬è¬ï¼\nåº—å“¡ï¼šä¸å®¢æ°£ã€‚ç¥æ‚¨æœ‰ç¾å¥½çš„ä¸€å¤©ã€‚",
                question: "é¡§å®¢é™¤äº†æ°´ä¹‹å¤–é‚„è²·äº†ä»€éº¼ï¼Ÿ",
                options: ["é¤…ä¹¾", "é›œèªŒ", "é¢ç´™", "å£é¦™ç³–"],
                correctAnswerIndex: 2,
                englishTranscript: "Customer: Hi, I'd like this bottled water and a pack of tissues.\nClerk: Okay, that's 45 NTD in total.\nCustomer: Here's 50. Do you have a bag?",
            },
            {
                topic: "Riding the MRT (æ­æ·é‹)",
                conversation: [
                    "Tourist: Excuse me, which line goes to Taipei Main Station?",
                    "Local: You need to take the Red Line. It's just two stops from here.",
                    "Tourist: The Red Line, two stops. Got it. Is it easy to transfer?",
                    "Local: Yes, very easy. All transfers are well-marked.",
                    "Tourist: Great! Thanks for the info.",
                    "Local: No problem, enjoy your ride!"
                ],
                chineseTranslation: "éŠå®¢ï¼šä¸å¥½æ„æ€ï¼Œå“ªæ¢ç·šåˆ°å°åŒ—è»Šç«™ï¼Ÿ\nç•¶åœ°äººï¼šä½ éœ€è¦æ­ç´…ç·šã€‚å¾é€™è£¡éå»åªæœ‰å…©ç«™ã€‚\néŠå®¢ï¼šç´…ç·šï¼Œå…©ç«™ã€‚çŸ¥é“äº†ã€‚è½‰ä¹˜æ–¹ä¾¿å—ï¼Ÿ\nç•¶åœ°äººï¼šæ˜¯çš„ï¼Œéå¸¸æ–¹ä¾¿ã€‚æ‰€æœ‰è½‰ä¹˜éƒ½æœ‰æ¸…æ¥šæ¨™ç¤ºã€‚\néŠå®¢ï¼šå¤ªå¥½äº†ï¼è¬è¬ä½ çš„è³‡è¨Šã€‚\nç•¶åœ°äººï¼šä¸å®¢æ°£ï¼Œç¥ä½ æ—…é€”æ„‰å¿«ï¼",
                question: "éŠå®¢éœ€è¦æ­ä¹˜å“ªæ¢æ·é‹ç·šå‰å¾€å°åŒ—è»Šç«™ï¼Ÿ",
                options: ["è—ç·š", "ç¶ ç·š", "ç´…ç·š", "æ£•ç·š"],
                correctAnswerIndex: 2,
                englishTranscript: "Tourist: Excuse me, which line goes to Taipei Main Station?\nLocal: You need to take the Red Line. It's just two stops from here.\nTourist: The Red Line, two stops. Got it. Is it easy to transfer?\nLocal: Yes, very easy. All transfers are well-marked.\nTourist: Great! Thanks for the info.\nLocal: No problem, enjoy your ride!"
            },
            {
                topic: "Booking Accommodation (é è¨‚ä½å®¿)",
                conversation: [
                    "Guest: Hello, I'd like to book a room for two nights, starting tomorrow.",
                    "Receptionist: Let me check. For how many people?",
                    "Guest: Just one person.",
                    "Receptionist: Okay, we have a standard single room available. The rate is 2,500 NTD per night.",
                    "Guest: Sounds good. I'll take it.",
                    "Receptionist: Excellent! Can I get your name, please?"
                ],
                chineseTranslation: "å®¢äººï¼šä½ å¥½ï¼Œæˆ‘æƒ³é è¨‚ä¸€é–“æˆ¿é–“ï¼Œæ˜å¤©é–‹å§‹ä½å…©æ™šã€‚\næ¥å¾…å“¡ï¼šè®“æˆ‘æŸ¥ä¸€ä¸‹ã€‚å¹¾å€‹äººï¼Ÿ\nå®¢äººï¼šåªæœ‰ä¸€å€‹äººã€‚\næ¥å¾…å“¡ï¼šå¥½çš„ï¼Œæˆ‘å€‘æœ‰ä¸€é–“æ¨™æº–å–®äººæˆ¿ã€‚æ¯æ™šè²»ç”¨æ˜¯æ–°å°å¹£2,500å…ƒã€‚\nå®¢äººï¼šè½èµ·ä¾†ä¸éŒ¯ã€‚æˆ‘è¨‚äº†ã€‚\næ¥å¾…å“¡ï¼šå¤ªå¥½äº†ï¼è«‹å•æ‚¨çš„å§“åæ˜¯ï¼Ÿ",
                question: "å®¢äººæƒ³é è¨‚å¹¾æ™šçš„æˆ¿é–“ï¼Ÿ",
                options: ["ä¸€æ™š", "å…©æ™š", "ä¸‰æ™š", "å››æ™š"],
                correctAnswerIndex: 1,
                englishTranscript: "Guest: Hello, I'd like to book a room for two nights, starting tomorrow.\nReceptionist: Let me check. For how many people?\nGuest: Just one person.\nReceptionist: Okay, we have a standard single room available. The rate is 2,500 NTD per night.\nGuest: Sounds good. I'll take it.\nReceptionist: Excellent! Can I get your name, please?"
            },
            {
                topic: "At a Bank/ATM (éŠ€è¡Œ/ææ¬¾æ©Ÿ)",
                conversation: [
                    "Customer: Excuse me, I'd like to exchange some currency.",
                    "Bank Teller: Certainly. What currency are you exchanging?",
                    "Customer: US dollars to New Taiwan dollars.",
                    "Bank Teller: Okay, please fill out this form. Do you have your passport?",
                    "Customer: Yes, here it is.",
                    "Bank Teller: Thank you. I'll process this for you."
                ],
                chineseTranslation: "é¡§å®¢ï¼šä¸å¥½æ„æ€ï¼Œæˆ‘æƒ³å…Œæ›ä¸€äº›è²¨å¹£ã€‚\néŠ€è¡Œæ«ƒå“¡ï¼šç•¶ç„¶ã€‚æ‚¨è¦å…Œæ›ä»€éº¼è²¨å¹£ï¼Ÿ\né¡§å®¢ï¼šç¾å…ƒå…Œæ›æ–°å°å¹£ã€‚\néŠ€è¡Œæ«ƒå“¡ï¼šå¥½çš„ï¼Œè«‹å¡«å¯«é€™ä»½è¡¨æ ¼ã€‚æ‚¨æœ‰å¸¶è­·ç…§å—ï¼Ÿ\né¡§å®¢ï¼šæ˜¯çš„ï¼Œåœ¨é€™è£¡ã€‚\néŠ€è¡Œæ«ƒå“¡ï¼šè¬è¬ã€‚æˆ‘æœƒç‚ºæ‚¨è¾¦ç†ã€‚",
                question: "é¡§å®¢æƒ³æŠŠä»€éº¼è²¨å¹£å…Œæ›æˆæ–°å°å¹£ï¼Ÿ",
                options: ["æ—¥åœ“", "æ­å…ƒ", "ç¾å…ƒ", "äººæ°‘å¹£"],
                correctAnswerIndex: 2,
                englishTranscript: "Customer: Excuse me, I'd like to exchange some currency.\nBank Teller: Certainly. What currency are you exchanging?\nCustomer: US dollars to New Taiwan dollars.\nBank Teller: Okay, please fill out this form. Do you have your passport?",
            }
        ];
        let currentScenarioIndex = 0;
        let selectedOptionIndex = -1; // To track the user's selected option for the quiz

        // Speaker voice configuration
        const speakerColors = ['text-blue-700', 'text-green-700', 'text-purple-700', 'text-red-700', 'text-indigo-700'];
        let speakerMap = {}; // Maps speaker name (e.g., "Tourist") to an index for color/voice
        let speakerVoiceMap = {}; // Maps speaker name to a SpeechSynthesisVoice object

        // --- Utility Functions ---

        /**
         * Displays a message in the global message box.
         * @param {string} message - The message to display.
         * @param {string} type - 'success', 'error', 'info', 'warning'. Determines styling.
         */
        function showMessageBox(message, type = 'info') {
            messageBox.textContent = message;
            messageBox.className = 'message-box show'; // Reset classes first
            if (type === 'success') {
                messageBox.classList.add('bg-green-100', 'border-green-400', 'text-green-700');
            } else if (type === 'error') {
                messageBox.classList.add('bg-red-100', 'border-red-400', 'text-red-700');
            } else if (type === 'warning') {
                messageBox.classList.add('bg-yellow-100', 'border-yellow-400', 'text-yellow-700');
            } else { // info
                messageBox.classList.add('bg-blue-100', 'border-blue-400', 'text-blue-700');
            }
            setTimeout(() => {
                messageBox.classList.remove('show');
            }, 5000); // Hide after 5 seconds
        }

        /**
         * Normalizes text for comparison (removes punctuation, converts to lowercase).
         * @param {string} text - The input text.
         * @returns {string} Normalized text.
         */
        function normalizeText(text) {
            return text.toLowerCase().replace(/[.,/#!$%^&*;:{}=\-_`~()?'"]/g, '').replace(/\s{2,}/g, ' ').trim();
        }

        /**
         * Plays a given audio blob.
         * @param {Blob} blob - The audio blob to play.
         */
        async function playAudioBlob(blob) {
            if (!blob) {
                showMessageBox('æ²’æœ‰éŸ³è¨Šå¯æ’­æ”¾ã€‚', 'warning');
                return;
            }
            try {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                const arrayBuffer = await blob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                if (sourceNode) { // Stop previous playback if any
                    sourceNode.stop();
                    sourceNode.disconnect();
                }

                sourceNode = audioContext.createBufferSource();
                sourceNode.buffer = audioBuffer;
                sourceNode.connect(audioContext.destination);
                sourceNode.start();
                showMessageBox('æ­£åœ¨æ’­æ”¾éŸ³è¨Š...', 'info');
            } catch (error) {
                console.error('Error playing audio blob:', error);
                showMessageBox('æ’­æ”¾éŸ³è¨Šå¤±æ•—ã€‚' + error.message, 'error');
            }
        }

        // --- Tab Switching Logic ---
        function showTab(tabId) {
            // Deactivate all tab buttons and hide all content sections
            document.querySelectorAll('.tab-button').forEach(btn => btn.classList.remove('active'));
            document.querySelectorAll('.content-section').forEach(section => section.classList.remove('active'));

            // Activate the selected tab button and show its content
            if (tabId === 'listening') {
                listeningTabBtn.classList.add('active');
                listeningContent.classList.add('active');
            } else if (tabId === 'speaking') {
                speakingTabBtn.classList.add('active');
                speakingContent.classList.add('active');
            }
        }

        listeningTabBtn.addEventListener('click', () => showTab('listening'));
        speakingTabBtn.addEventListener('click', () => showTab('speaking'));

        // --- Listening Practice Functions ---

        const playConversationBtn = document.getElementById('playConversationBtn');
        const pauseConversationBtn = document.getElementById('pauseConversationBtn');
        const stopConversationBtn = document.getElementById('stopConversationBtn'); // New stop button
        const nextScenarioBtn = document.getElementById('nextScenarioBtn');
        const conversationDisplay = document.getElementById('conversationDisplay');
        const scenarioQuestionEl = document.getElementById('scenarioQuestion');
        const optionsContainer = document.getElementById('optionsContainer');
        const checkAnswerBtn = document.getElementById('checkAnswerBtn');
        const showTranscriptBtn = document.getElementById('showTranscriptBtn');
        const quizFeedback = document.getElementById('quizFeedback');
        const quizTranscriptDisplay = document.getElementById('quizTranscriptDisplay');
        const usAccentBtn = document.getElementById('usAccentBtn');
        const ukAccentBtn = document.getElementById('ukAccentBtn');

        /**
         * Selects the best available voice for a given language tag and preference.
         * Prioritizes Google voices, then Microsoft, then generic.
         * @param {string} langTag - The language tag (e.g., 'en-US', 'en-GB').
         * @returns {SpeechSynthesisVoice|null} The selected voice or null if none found.
         */
        function selectBestVoice(langTag) {
            const voices = synth.getVoices();
            const filteredVoices = voices.filter(voice => voice.lang === langTag);

            // Prioritize Google voices
            let voice = filteredVoices.find(v => v.name.includes('Google') && !v.name.includes('Female'));
            if (voice) return voice;
            voice = filteredVoices.find(v => v.name.includes('Google')); // Any Google voice

            // Then Microsoft voices
            if (!voice) voice = filteredVoices.find(v => v.name.includes('Microsoft') && !v.name.includes('Female'));
            if (!voice) voice = filteredVoices.find(v => v.name.includes('Microsoft')); // Any Microsoft voice

            // Fallback to any voice for the language
            if (!voice) voice = filteredVoices[0];

            return voice || null;
        }

        /**
         * Loads available voices and assigns them to speakerVoiceMap.
         */
        function loadVoices() {
            // Ensure voices are loaded before attempting to select
            if (synth.getVoices().length === 0) {
                synth.onvoiceschanged = loadVoices; // Re-run when voices are loaded
                return;
            }

            let voice1, voice2;

            if (currentAccent === 'en-GB') {
                voice1 = selectBestVoice('en-GB');
                voice2 = selectBestVoice('en-GB');
            } else { // en-US
                voice1 = selectBestVoice('en-US');
                voice2 = selectBestVoice('en-US');
            }

            // Ensure voice2 is different from voice1 if possible
            const allVoicesForAccent = synth.getVoices().filter(v => v.lang === currentAccent);
            if (voice1 && voice2 && voice1.name === voice2.name && allVoicesForAccent.length > 1) {
                voice2 = allVoicesForAccent.find(v => v.name !== voice1.name) || voice1;
            } else if (!voice1 && allVoicesForAccent.length > 0) { // Fallback if selectBestVoice failed
                voice1 = allVoicesForAccent[0];
                voice2 = allVoicesForAccent.length > 1 ? allVoicesForAccent[1] : allVoicesForAccent[0];
            } else if (!voice1 && !voice2) { // Absolute fallback to any English voices
                const englishVoices = synth.getVoices().filter(v => v.lang.startsWith('en-'));
                if (englishVoices.length >= 2) {
                    voice1 = englishVoices[0];
                    voice2 = englishVoices[1];
                } else if (englishVoices.length === 1) {
                    voice1 = englishVoices[0];
                    voice2 = englishVoices[0];
                } else {
                    console.warn('No English voices found. Speech synthesis may not work.');
                }
            }

            speaker1Voice = voice1;
            speaker2Voice = voice2;

            // console.log("Speaker 1 Voice:", speaker1Voice ? speaker1Voice.name : 'N/A');
            // console.log("Speaker 2 Voice:", speaker2Voice ? speaker2Voice.name : 'N/A');
        }

        // Ensure voices are loaded when they change or initially
        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = loadVoices;
        }
        loadVoices(); // Call initially in case voices are already loaded

        /**
         * Speaks the given text using SpeechSynthesisUtterance and returns a Promise.
         * @param {string} text - The text to speak.
         * @param {SpeechSynthesisVoice} voice - The voice to use.
         * @returns {Promise<void>} A promise that resolves when speech ends or rejects on error.
         */
        function speakText(text, voice) {
            return new Promise((resolve, reject) => {
                currentUtterance = new SpeechSynthesisUtterance(text);
                currentUtterance.lang = currentAccent; // Use selected accent for language
                currentUtterance.voice = voice;
                currentUtterance.onend = () => {
                    resolve();
                };
                currentUtterance.onerror = (event) => {
                    console.error('SpeechSynthesisUtterance.onerror', event);
                    showMessageBox('èªéŸ³åˆæˆå¤±æ•—ã€‚æ‚¨çš„ç€è¦½å™¨å¯èƒ½ä¸æ”¯æ´æˆ–æœ‰å•é¡Œã€‚', 'error');
                    reject(event); // Reject the promise on error
                };
                try {
                    synth.speak(currentUtterance);
                } catch (e) {
                    console.error('Error calling synth.speak:', e);
                    showMessageBox('èªéŸ³åˆæˆå•Ÿå‹•å¤±æ•—ã€‚', 'error');
                    reject(e); // Reject if speak itself throws an error
                }
            });
        }

        /**
         * Displays the current scenario's conversation, question, and options.
         */
        function displayCurrentScenario() {
            const scenario = listeningScenarios[currentScenarioIndex];
            conversationDisplay.innerHTML = '<p class="text-gray-500 italic">é»æ“Šã€Œæ’­æ”¾å°è©±ã€é–‹å§‹ã€‚</p>'; // Clear and reset
            scenarioQuestionEl.textContent = `å•é¡Œï¼š${scenario.question}`;
            scenarioQuestionEl.classList.add('hidden'); // Hide until conversation is played

            optionsContainer.innerHTML = ''; // Clear previous options
            scenario.options.forEach((option, index) => {
                const button = document.createElement('button');
                button.className = 'option-button btn-secondary';
                button.textContent = option;
                button.dataset.index = index;
                button.addEventListener('click', () => selectOption(index));
                optionsContainer.appendChild(button);
            });

            checkAnswerBtn.disabled = true;
            showTranscriptBtn.disabled = true;
            quizFeedback.textContent = '';
            quizTranscriptDisplay.classList.add('hidden');
            selectedOptionIndex = -1; // Reset selected option

            // Reset speaker map for new scenario
            speakerMap = {};
        }

        /**
         * Plays the conversation line by line.
         */
        async function playConversation() {
            const scenario = listeningScenarios[currentScenarioIndex];
            const conversationLines = scenario.conversation;
            conversationDisplay.innerHTML = ''; // Clear initial message
            synth.cancel(); // Always cancel previous speech before starting new
            
            playConversationBtn.disabled = true; // Disable play button during playback
            nextScenarioBtn.disabled = true; // Disable next scenario during playback
            pauseConversationBtn.disabled = false; // Enable pause button
            stopConversationBtn.disabled = false; // Enable stop button
            pauseConversationBtn.textContent = 'æš«åœ â¸ï¸';
            isConversationPlaying = true;
            isConversationPaused = false;

            let speakerCounter = 0;
            for (let i = 0; i < conversationLines.length; i++) {
                // If stopped by user, break the loop
                if (!isConversationPlaying) {
                    break;
                }

                // Handle pause state: wait until resumed
                while (isConversationPaused && isConversationPlaying) {
                    await new Promise(resolve => setTimeout(resolve, 100)); // Poll every 100ms
                }

                // Check again if stopped after pause
                if (!isConversationPlaying) {
                    break;
                }

                const line = conversationLines[i];
                const speakerMatch = line.match(/^([^:]+):/);
                let speakerName = 'Unknown';
                let actualSpeech = line;

                if (speakerMatch) {
                    speakerName = speakerMatch[1].trim();
                    actualSpeech = line.substring(speakerMatch[0].length).trim();
                }

                if (!(speakerName in speakerMap)) {
                    speakerMap[speakerName] = speakerCounter % 2; // Assign to speaker 0 or 1
                    speakerCounter++;
                }

                const speakerIdx = speakerMap[speakerName];
                const speakerColorClass = speakerColors[speakerIdx % speakerColors.length]; // Use modular arithmetic for color
                const voiceToUse = (speakerIdx === 0) ? speaker1Voice : speaker2Voice;

                const p = document.createElement('p');
                p.className = `conversation-line text-gray-800 ${speakerColorClass}`;
                p.textContent = line;
                conversationDisplay.appendChild(p);
                conversationDisplay.scrollTop = conversationDisplay.scrollHeight; // Scroll to bottom

                try {
                    await speakText(actualSpeech, voiceToUse);
                } catch (error) {
                    console.error("Error speaking line:", error);
                    // Continue to next line even if one fails
                }

                // Add a small delay between lines for better pacing, unless paused or stopped
                if (isConversationPlaying && !isConversationPaused) {
                    await new Promise(resolve => setTimeout(resolve, 500));
                }
            }

            // After conversation (or if stopped), reset controls
            playConversationBtn.disabled = false; // Re-enable play button
            nextScenarioBtn.disabled = false; // Re-enable next scenario button
            pauseConversationBtn.disabled = true; // Disable pause after conversation finishes
            stopConversationBtn.disabled = true; // Disable stop after conversation finishes
            pauseConversationBtn.textContent = 'æš«åœ â¸ï¸';
            isConversationPlaying = false;
            isConversationPaused = false;

            synth.cancel(); // Ensure all speech is stopped at the end

            showMessageBox('å°è©±æ’­æ”¾å®Œç•¢ã€‚è«‹é¸æ“‡ç­”æ¡ˆã€‚', 'info');
            scenarioQuestionEl.classList.remove('hidden');
            optionsContainer.querySelectorAll('.option-button').forEach(btn => btn.disabled = false);
        }

        /**
         * Handles option selection for the quiz.
         * @param {number} index - The index of the selected option.
         */
        function selectOption(index) {
            selectedOptionIndex = index;
            optionsContainer.querySelectorAll('.option-button').forEach((btn, idx) => {
                btn.classList.remove('selected');
                if (idx === index) {
                    btn.classList.add('selected');
                }
            });
            checkAnswerBtn.disabled = false; // Enable check answer button
        }

        playConversationBtn.addEventListener('click', playConversation);

        pauseConversationBtn.addEventListener('click', () => {
            if (synth.speaking && !isConversationPaused) {
                synth.pause();
                isConversationPaused = true;
                pauseConversationBtn.textContent = 'ç¹¼çºŒæ’­æ”¾ â–¶ï¸';
                showMessageBox('å°è©±å·²æš«åœã€‚', 'info');
            } else if (synth.paused && isConversationPaused) {
                synth.resume();
                isConversationPaused = false;
                pauseConversationBtn.textContent = 'æš«åœ â¸ï¸';
                showMessageBox('å°è©±å·²æ¢å¾©ã€‚', 'info');
            }
        });

        stopConversationBtn.addEventListener('click', () => {
            if (synth.speaking || synth.paused) {
                synth.cancel(); // Stop any ongoing speech
            }
            isConversationPlaying = false;
            isConversationPaused = false;
            playConversationBtn.disabled = false;
            nextScenarioBtn.disabled = false;
            pauseConversationBtn.disabled = true;
            stopConversationBtn.disabled = true;
            pauseConversationBtn.textContent = 'æš«åœ â¸ï¸';
            showMessageBox('å°è©±å·²åœæ­¢ã€‚', 'info');
            // Re-display scenario to clear conversation text and reset state
            displayCurrentScenario();
        });


        nextScenarioBtn.addEventListener('click', () => {
            if (synth.speaking || synth.paused) {
                synth.cancel(); // Stop any ongoing speech
                isConversationPlaying = false;
                isConversationPaused = false;
                pauseConversationBtn.disabled = true;
                stopConversationBtn.disabled = true;
                pauseConversationBtn.textContent = 'æš«åœ â¸ï¸';
            }
            currentScenarioIndex = (currentScenarioIndex + 1) % listeningScenarios.length;
            displayCurrentScenario();
            showMessageBox('è¼‰å…¥ä¸‹ä¸€å€‹æƒ…å¢ƒã€‚', 'info');
        });

        checkAnswerBtn.addEventListener('click', () => {
            if (selectedOptionIndex === -1) {
                showMessageBox('è«‹å…ˆé¸æ“‡ä¸€å€‹ç­”æ¡ˆã€‚', 'warning');
                return;
            }

            const scenario = listeningScenarios[currentScenarioIndex];
            if (selectedOptionIndex === scenario.correctAnswerIndex) {
                quizFeedback.textContent = 'ç­”å°äº†ï¼å¤ªæ£’äº†ï¼ğŸ‰';
                quizFeedback.className = 'text-lg font-semibold mt-4 text-green-600';
                showMessageBox('æ­å–œï¼ç­”æ¡ˆæ­£ç¢ºï¼', 'success');
            } else {
                quizFeedback.textContent = 'ç­”éŒ¯äº†ã€‚è«‹å†è©¦ä¸€æ¬¡æˆ–é¡¯ç¤ºä¸­æ–‡åŸæ–‡ã€‚ğŸ¤”';
                quizFeedback.className = 'text-lg font-semibold mt-4 text-red-600';
                showMessageBox('ç­”æ¡ˆä¸æ­£ç¢ºã€‚', 'error');
            }
            checkAnswerBtn.disabled = true; // Disable check answer after one attempt
            showTranscriptBtn.disabled = false; // Enable show transcript
            optionsContainer.querySelectorAll('.option-button').forEach(btn => btn.disabled = true); // Disable options after checking
        });

        showTranscriptBtn.addEventListener('click', () => {
            const scenario = listeningScenarios[currentScenarioIndex];
            quizTranscriptDisplay.textContent = `ä¸­æ–‡åŸæ–‡ï¼š\n${scenario.chineseTranslation}`;
            quizTranscriptDisplay.classList.remove('hidden');
        });

        usAccentBtn.addEventListener('click', () => {
            currentAccent = 'en-US';
            usAccentBtn.classList.add('btn-primary');
            usAccentBtn.classList.remove('btn-secondary');
            ukAccentBtn.classList.add('btn-secondary');
            ukAccentBtn.classList.remove('btn-primary');
            loadVoices(); // Reload voices based on new accent preference
            showMessageBox('å·²åˆ‡æ›åˆ°ç¾å¼å£éŸ³ ğŸ‡ºğŸ‡¸ã€‚', 'info');
        });

        ukAccentBtn.addEventListener('click', () => {
            currentAccent = 'en-GB';
            ukAccentBtn.classList.add('btn-primary');
            ukAccentBtn.classList.remove('btn-secondary');
            usAccentBtn.classList.add('btn-secondary');
            usAccentBtn.classList.remove('btn-primary');
            loadVoices(); // Reload voices based on new accent preference
            showMessageBox('å·²åˆ‡æ›åˆ°è‹±å¼å£éŸ³ ğŸ‡¬ğŸ‡§ã€‚', 'info');
        });

        // --- Speaking Practice Functions (unchanged from previous version, only UI text updated) ---

        const targetSentenceEl = document.getElementById('targetSentence');
        const recordBtn = document.getElementById('recordBtn');
        const stopRecordBtn = document.getElementById('stopRecordBtn');
        const playOriginalBtn = document.getElementById('playOriginalBtn');
        const playMyRecordingBtn = document.getElementById('playMyRecordingBtn');
        const nextSpeakingSentenceBtn = document.getElementById('nextSpeakingSentenceBtn');
        const userTranscriptionEl = document.getElementById('userTranscription');
        const speakingFeedbackEl = document.getElementById('speakingFeedback');

        const startFreeSpeakBtn = document.getElementById('startFreeSpeakBtn');
        const stopFreeSpeakBtn = document.getElementById('stopFreeSpeakBtn');
        const freeSpeechTranscriptionEl = document.getElementById('freeSpeechTranscription');

        /**
         * Initializes SpeechRecognition.
         * @param {boolean} continuous - If true, recognition continues until stopped.
         * @param {boolean} interimResults - If true, interim results are returned.
         * @param {Function} onResult - Callback for when a result is received.
         * @param {Function} onEnd - Callback for when recognition ends.
         * @param {Function} onError - Callback for when an error occurs.
         * @returns {SpeechRecognition} The recognition object.
         */
        function initSpeechRecognition(continuous, interimResults, onResult, onEnd, onError) {
            if (!('webkitSpeechRecognition' in window)) {
                showMessageBox('èªéŸ³è¾¨è­˜ä¸æ”¯æ´æ­¤ç€è¦½å™¨ã€‚è«‹ä½¿ç”¨ Chrome æˆ– Edgeã€‚', 'error');
                return null;
            }
            const SpeechRecognition = window.webkitSpeechRecognition;
            const newRecognition = new SpeechRecognition();
            newRecognition.continuous = continuous;
            newRecognition.interimResults = interimResults;
            newRecognition.lang = currentAccent; // Use selected accent for speech recognition

            newRecognition.onresult = onResult;
            newRecognition.onend = onEnd;
            newRecognition.onerror = onError;

            return newRecognition;
        }

        /**
         * Starts audio recording using MediaRecorder.
         * @param {Function} onDataAvailable - Callback for when audio data is available.
         * @param {Function} onStop - Callback for when recording stops.
         */
        async function startRecording(onDataAvailable, onStop) {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                    onDataAvailable(event.data);
                };

                mediaRecorder.onstop = () => {
                    recordedAudioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    onStop(recordedAudioBlob);
                    // Stop the microphone stream tracks
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                showMessageBox('éŒ„éŸ³å·²é–‹å§‹...', 'info');
                recordBtn.disabled = true;
                stopRecordBtn.disabled = false;
                playMyRecordingBtn.disabled = true; // Disable playback until recording is done
                playOriginalBtn.disabled = true; // Disable original playback during recording
                nextSpeakingSentenceBtn.disabled = true; // Disable next sentence during recording
            } catch (error) {
                console.error('Error accessing microphone:', error);
                showMessageBox('ç„¡æ³•å­˜å–éº¥å…‹é¢¨ã€‚è«‹ç¢ºèªå·²æˆäºˆæ¬Šé™ã€‚' + error.message, 'error');
                recordBtn.disabled = false;
                stopRecordBtn.disabled = true;
            }
        }

        /**
         * Stops the current audio recording.
         */
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                showMessageBox('éŒ„éŸ³å·²åœæ­¢ã€‚', 'info');
                recordBtn.disabled = false;
                stopRecordBtn.disabled = true;
                playMyRecordingBtn.disabled = false; // Enable playback after recording
                playOriginalBtn.disabled = false; // Enable original playback after recording
                nextSpeakingSentenceBtn.disabled = false; // Enable next sentence after recording
            }
        }

        // --- Speaking Practice Event Listeners ---

        nextSpeakingSentenceBtn.addEventListener('click', () => {
            currentSpeakingSentenceIndex = (currentSpeakingSentenceIndex + 1) % speakingSentences.length;
            targetSentenceEl.textContent = speakingSentences[currentSpeakingSentenceIndex];
            userTranscriptionEl.textContent = '';
            speakingFeedbackEl.textContent = '';
            playOriginalBtn.disabled = false; // Enable play original for new sentence
            playMyRecordingBtn.disabled = true; // Disable play my recording until new recording
            recordedAudioBlob = null; // Clear previous recording
            showMessageBox('è¼‰å…¥ä¸‹ä¸€å€‹å£èªªå¥å­ã€‚', 'info');
        });

        recordBtn.addEventListener('click', async () => {
            speakingFeedbackEl.textContent = ''; // Clear previous feedback
            userTranscriptionEl.textContent = 'æ­£åœ¨è†è½...';

            // Start recording audio
            await startRecording(
                (data) => { /* console.log('Audio data available:', data); */ },
                (blob) => {
                    recordedAudioBlob = blob;
                    playMyRecordingBtn.disabled = false;
                }
            );

            // Start speech recognition
            recognition = initSpeechRecognition(
                false, // Not continuous for sentence repetition
                true,  // Interim results for live feedback
                (event) => {
                    let interimTranscript = '';
                    let finalTranscript = '';
                    for (let i = event.resultIndex; i < event.results.length; ++i) {
                        const transcript = event.results[i][0].transcript;
                        if (event.results[i].isFinal) {
                            finalTranscript += transcript;
                        } else {
                            interimTranscript += transcript;
                        }
                    }
                    userTranscriptionEl.textContent = finalTranscript || interimTranscript;
                },
                () => {
                    // When speech recognition ends
                    const targetText = normalizeText(targetSentenceEl.textContent);
                    const userText = normalizeText(userTranscriptionEl.textContent);

                    if (userText === targetText) {
                        speakingFeedbackEl.textContent = 'å¤ªæ£’äº†ï¼æ‚¨çš„ç™¼éŸ³å¾ˆæ¸…æ™°ã€‚';
                        speakingFeedbackEl.className = 'text-lg font-semibold mt-4 text-green-600';
                    } else if (userText.includes(targetText) || targetText.includes(userText)) {
                         speakingFeedbackEl.textContent = 'ä¸éŒ¯çš„å˜—è©¦ï¼æœ‰äº›è©å¯èƒ½ä¸å°ã€‚è«‹èˆ‡åŸæ–‡æ¯”è¼ƒã€‚';
                         speakingFeedbackEl.className = 'text-lg font-semibold mt-4 text-orange-600';
                    }
                    else {
                        speakingFeedbackEl.textContent = 'ç¹¼çºŒç·´ç¿’ï¼ç›¡é‡æ›´æ¥è¿‘å¥å­ã€‚';
                        speakingFeedbackEl.className = 'text-lg font-semibold mt-4 text-red-600';
                    }
                    // Highlight differences (simple word-by-word comparison)
                    const targetWords = targetText.split(' ');
                    const userWords = userText.split(' ');
                    let highlightedText = '';
                    for (let i = 0; i < targetWords.length || i < userWords.length; i++) {
                        const targetWord = targetWords[i] || '';
                        const userWord = userWords[i] || '';
                        if (targetWord === userWord && targetWord !== '') {
                            highlightedText += `<span class="text-green-700">${targetWord}</span> `;
                        } else if (userWord !== '') {
                            highlightedText += `<span class="text-red-700">${userWord}</span> `;
                        }
                    }
                    userTranscriptionEl.innerHTML = highlightedText.trim() || userTranscriptionEl.textContent;

                    showMessageBox('èªéŸ³è¾¨è­˜çµæŸã€‚', 'info');
                },
                (event) => {
                    console.error('Speech recognition error:', event.error);
                    showMessageBox('èªéŸ³è¾¨è­˜éŒ¯èª¤ï¼š' + event.error, 'error');
                    userTranscriptionEl.textContent = 'è½‰éŒ„éŒ¯èª¤ã€‚';
                }
            );
            if (recognition) {
                recognition.start();
                showMessageBox('èªéŸ³è¾¨è­˜å·²é–‹å§‹...', 'info');
            }
        });

        stopRecordBtn.addEventListener('click', () => {
            stopRecording();
            if (recognition && recognition.recognizing) {
                recognition.stop(); // Stop speech recognition
            }
        });

        playOriginalBtn.addEventListener('click', () => {
            const sentence = targetSentenceEl.textContent;
            if (sentence && sentence !== "é»æ“Šã€Œä¸‹ä¸€å€‹å¥å­ã€é–‹å§‹ã€‚") {
                speakText(sentence, speaker1Voice); // Use a default voice for original playback
            } else {
                showMessageBox('æ²’æœ‰åŸæ–‡å¯æ’­æ”¾ã€‚è«‹é»æ“Šã€Œä¸‹ä¸€å€‹å¥å­ã€ã€‚', 'warning');
            }
        });

        playMyRecordingBtn.addEventListener('click', () => {
            playAudioBlob(recordedAudioBlob);
        });

        // --- Free Speaking Mode (unchanged from previous version, only UI text updated) ---

        let freeSpeechRecognition = null;

        startFreeSpeakBtn.addEventListener('click', () => {
            freeSpeechTranscriptionEl.textContent = 'æ­£åœ¨è†è½æ‚¨çš„è‡ªç”±èªªè©±...';
            startFreeSpeakBtn.disabled = true;
            stopFreeSpeakBtn.disabled = false;

            freeSpeechRecognition = initSpeechRecognition(
                true,  // Continuous for free speaking
                true,  // Interim results
                (event) => {
                    let interimTranscript = '';
                    let finalTranscript = '';
                    for (let i = event.resultIndex; i < event.results.length; ++i) {
                        const transcript = event.results[i][0].transcript;
                        if (event.results[i].isFinal) {
                            finalTranscript += transcript;
                        } else {
                            interimTranscript += transcript;
                        }
                    }
                    freeSpeechTranscriptionEl.textContent = finalTranscript || interimTranscript;
                },
                () => {
                    showMessageBox('è‡ªç”±èªªè©±æœƒè©±çµæŸã€‚', 'info');
                    startFreeSpeakBtn.disabled = false;
                    stopFreeSpeakBtn.disabled = true;
                },
                (event) => {
                    console.error('Free speech recognition error:', event.error);
                    showMessageBox('è‡ªç”±èªªè©±èªéŸ³è¾¨è­˜éŒ¯èª¤ï¼š' + event.error, 'error');
                    freeSpeechTranscriptionEl.textContent = 'è½‰éŒ„éŒ¯èª¤ã€‚';
                    startFreeSpeakBtn.disabled = false;
                    stopFreeSpeakBtn.disabled = true;
                }
            );
            if (freeSpeechRecognition) {
                freeSpeechRecognition.start();
                showMessageBox('è‡ªç”±èªªè©±å·²é–‹å§‹ã€‚ç¾åœ¨è«‹èªªè©±ï¼', 'info');
            }
        });

        stopFreeSpeakBtn.addEventListener('click', () => {
            if (freeSpeechRecognition && freeSpeechRecognition.recognizing) {
                freeSpeechRecognition.stop();
            }
            startFreeSpeakBtn.disabled = false;
            stopFreeSpeakBtn.disabled = true;
        });

        // --- Initial Load ---
        window.onload = () => {
            // Set initial content for speaking practice
            targetSentenceEl.textContent = speakingSentences[currentSpeakingSentenceIndex];
            // Display the first listening scenario
            displayCurrentScenario();
            showMessageBox('æ­¡è¿ä½¿ç”¨æ‚¨çš„è‹±èªå­¸ç¿’æ‡‰ç”¨ç¨‹å¼ï¼', 'info');
        };

    </script>
</body>
</html>
